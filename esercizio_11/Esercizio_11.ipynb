{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9288c007-860e-4bca-a12a-036fd2f9d7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import get_custom_objects, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e8b8db-75ca-475d-869f-0332d4b14201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"  # mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e985bdbe-6551-43e2-b667-11d129f12f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotCurrentEstimate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_valid, y_valid):\n",
    "        \"\"\"Keras Callback which plot current model estimate against reference target\"\"\"\n",
    "\n",
    "        # convert numpy arrays into lists for plotting purposes\n",
    "        self.x_valid = list(x_valid[:])\n",
    "        self.y_valid = list(y_valid[:])\n",
    "        self.iter = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        temp = self.model.predict(self.x_valid, batch_size=None, verbose=False, steps=None)\n",
    "        self.y_curr = list(temp[:])  # convert numpy array into list\n",
    "\n",
    "        self.iter += 1\n",
    "        if self.iter % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            self.eplot = plt.subplot(1, 1, 1)\n",
    "            self.eplot.clear()\n",
    "            self.eplot.scatter(\n",
    "                self.x_valid, self.y_curr, color=\"blue\", s=4, marker=\"o\", label=\"estimate\",\n",
    "            )\n",
    "            self.eplot.scatter(self.x_valid, self.y_valid, color=\"red\", s=4, marker=\"x\", label=\"valid\")\n",
    "            self.eplot.legend()\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8d6b76-94f6-40a6-9b99-74e7ceee2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(model, history, row):\n",
    "\n",
    "    ax[row, 0].plot(history.history[\"loss\"], label=\"Train\")\n",
    "    ax[row, 0].plot(history.history[\"val_loss\"], label=\"Test\")\n",
    "    ax[row, 0].title.set_text(\"Model loss\")\n",
    "    ax[row, 0].set_xlabel(\"Epoch\")\n",
    "    ax[row, 0].legend()\n",
    "    ax[row, 0].grid(True)\n",
    "\n",
    "    x_predicted = np.linspace(-1, 1, 100)\n",
    "    y_predicted = model.predict(x_predicted)\n",
    "    ax[row, 1].scatter(x_predicted, y_predicted, color=\"r\", s=6, label=\"Prediction\")\n",
    "    ax[row, 1].scatter(x_valid, y_valid, s=2, label=\"Data\")\n",
    "    ax[row, 1].plot(x_valid, y_target, label=\"Theory\")\n",
    "    ax[row, 1].title.set_text(\"Prediction\")\n",
    "    ax[row, 1].legend()\n",
    "    ax[row, 1].grid(True)\n",
    "    ax[row, 1].set_xticklabels([])\n",
    "    ax[row, 1].set_yticklabels([])\n",
    "\n",
    "    lim = 1.25\n",
    "    x_predicted = np.linspace(-lim, lim, 100)\n",
    "    y_predicted = model.predict(x_predicted)\n",
    "    x_extended = np.linspace(-lim, lim, 100)\n",
    "    y_extended = polynomial(x_extended)\n",
    "    ax[row, 2].scatter(x_predicted, y_predicted, color=\"r\", label=\"Guess\")\n",
    "    ax[row, 2].plot(x_extended, y_extended, label=\"Theory\")\n",
    "    ax[row, 2].legend()\n",
    "    ax[row, 2].title.set_text(\"Prediction on Extended Range\")\n",
    "    ax[row, 2].grid(True)\n",
    "    #     ax[row, 2].set_xticklabels([])\n",
    "    ax[row, 2].set_yticklabels([])\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01bb916-a8ba-426a-87f7-202b0fb82456",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-431b8220336e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m callbacks = [\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mPlotCurrentEstimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTerminateOnNaN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_valid' is not defined"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    PlotCurrentEstimate(x_valid, y_valid),\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed4e223-b372-42a4-8f37-46b8f0b2e326",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 11.1 Practice on Linear Regression\n",
    "\n",
    "I trained a neural network (NN) on the labeled dataset $(x,y$ where $y_i = f(x_i) + \\eta_i,$  $f(x) = mx + b$ and $\\eta_i$ is a sample of normally distributed random noise.\n",
    "\n",
    "In the end, we would like the NN to predict a $y_i$ given a $x_i$. This prediction will be subject to error due to the random noise, but the NN will attempt to find the parameters that allow it to predict the entire training dataset. \n",
    "\n",
    "\n",
    "The assignment notebook uses the following parameters:\n",
    "- 1 neuron\n",
    "- batch size of 32\n",
    "- 50 epochs\n",
    "- 500/50 training and validation\n",
    "\n",
    "To test these parameters, I chose to challenge the NN with $\\sigma = 2.0$.\n",
    "\n",
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf5a412-8580-45ad-a425-f41fa2a65716",
   "metadata": {},
   "source": [
    "![](figs/original_loss.png)\n",
    "\n",
    "![](figs/original_fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303146fa-b473-489e-8011-d452f9fd1f44",
   "metadata": {},
   "source": [
    "The plateau in the loss/cost curve suggests that improving the model would require more than simply increasing the number of epochs. I'll try increasing the number of training points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a34c5-1b28-4fa2-bdc7-fc55bdafd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target parameters of f(x) = m*x + b\n",
    "m = 2  # slope\n",
    "b = 1  # intersect\n",
    "\n",
    "# noise on data\n",
    "sigma = 2.0\n",
    "\n",
    "N_train = 1000\n",
    "# N_valid = N_train / 10\n",
    "\n",
    "# generate training inputs\n",
    "np.random.seed(0)\n",
    "x_train = np.random.uniform(-1, 1, N_train)\n",
    "x_valid = np.random.uniform(-1, 1, int(N_train / 10))\n",
    "x_valid.sort()\n",
    "\n",
    "y_target = m * x_valid + b  # ideal (target) linear function (noise = 0)\n",
    "\n",
    "y_train = np.random.normal(m * x_train + b, sigma)\n",
    "\n",
    "# actual measures from which we want to guess regression parameters\n",
    "y_valid = np.random.normal(m * x_valid + b, sigma)\n",
    "\n",
    "# plot validation and target dataset\n",
    "plt.plot(x_valid, y_target, label=\"target\")\n",
    "plt.scatter(x_valid, y_valid, color=\"r\", label=\"validation data\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973355f-bd59-4fb3-b9e3-9cd462f2141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model._name = \"SeqModel\"\n",
    "model.add(Dense(1, input_shape=(1,)))\n",
    "\n",
    "# compile the model choosing optimizer, loss and metrics objects\n",
    "model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "# get a summary of our composed model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c086f-670e-4f55-a513-8c025c6ff766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=15, mode=\"auto\", verbose=1),\n",
    "    PlotCurrentEstimate(x_valid, y_valid),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421346a0-a13b-4b11-b1b5-ac0e78439cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea is to shuffle input before at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1db2c-e0e6-444e-9434-d262b8f44539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check weights\n",
    "print(\"Original m and b:\")\n",
    "print(m, b)\n",
    "print(\"Get m and b: \")\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d0362-3e56-4d49-85b6-1c4bde2043f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into training history\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.grid(True)\n",
    "# plt.savefig('figs/original_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fe8ba-9760-4f5e-b896-4b44cd5f2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to make a prediction\n",
    "x_predicted = np.random.uniform(-1, 1, 100)\n",
    "y_predicted = model.predict(x_predicted)\n",
    "plt.scatter(x_predicted, y_predicted, color=\"r\")\n",
    "plt.plot(x_valid, y_target)\n",
    "plt.grid(True)\n",
    "# plt.savefig('figs/original_fit.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0fc122-7391-4b04-8403-68b18e054cef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 11.2 Noisy Polynomial\n",
    "\n",
    "$f(x)=4-3x-2x^2+3x^3 $ for $x \\in [-1,1]$.\n",
    "\n",
    "Try exploring:\n",
    "\n",
    "- the number of layers\n",
    "- the number of neurons in each layer\n",
    "- the activation function\n",
    "- the optimizer\n",
    "- the loss function\n",
    "\n",
    "I'd like to find the simplest network that can solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddf648-8a7e-4529-a779-98aca9b8323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(x):\n",
    "    p = [3, -2, -3, 4]\n",
    "    return p[0] * x ** 3 + p[1] * x ** 2 + p[2] * x + p[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776bf540-318f-44dd-83f9-8659a89e9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise\n",
    "sigma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654381d9-5dce-4bcd-855f-06e2e0d80a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 5000\n",
    "# generate training inputs\n",
    "np.random.seed(0)\n",
    "x_train = np.random.uniform(-1, 1, N_train)\n",
    "x_valid = np.random.uniform(-1, 1, int(N_train / 10))\n",
    "x_valid.sort()\n",
    "\n",
    "y_target = polynomial(x_valid)  # ideal (target) linear function\n",
    "y_train = np.random.normal(polynomial(x_train), sigma)  # training data\n",
    "y_valid = np.random.normal(polynomial(x_valid), sigma)  # validation data\n",
    "\n",
    "# plot validation and target dataset\n",
    "plt.plot(x_valid, y_target, label=\"target\")\n",
    "plt.scatter(x_valid, y_valid, s=5, color=\"r\", label=\"validation data\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebe791-977c-4040-a71e-147df28f0bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc110f-2ec8-4830-b1cb-7c08576b6e40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploration of number of layers and neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea42802-6845-4af2-ba4e-54386f29c047",
   "metadata": {},
   "source": [
    "### Model A\n",
    "Model A is the neural network used in the previous example. It does a poor job and is only capable of fitting a line to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c9be1-c122-4efe-abb4-a58caa4fde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = Sequential()\n",
    "model_a._name = \"model_a\"\n",
    "model_a.add(Dense(units=1, input_dim=1, activation=\"relu\"))\n",
    "model_a.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_a.summary()\n",
    "\n",
    "history_model_a = model_a.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c30269-e0e7-471c-9447-55dd7815008d",
   "metadata": {},
   "source": [
    "### Model B\n",
    "\n",
    "Model B has a 1-5-1 structure equaling 16 parameters. \n",
    "\n",
    "$(5 + 5) + (5 + 1) = 16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03064d70-9ba7-4b5d-86ea-03b9297b1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network B\n",
    "model_b = Sequential()\n",
    "model_b._name = \"model_b\"\n",
    "model_b.add(Dense(units=5, input_dim=1, activation=\"relu\"))\n",
    "model_b.add(Dense(units=1, activation=\"relu\"))\n",
    "model_b.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_b.summary()\n",
    "\n",
    "history_model_b = model_b.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ff4d3-844e-4a95-8070-bf243b27ca4a",
   "metadata": {},
   "source": [
    "### Model C\n",
    "\n",
    "Will more neurons equal better results? Model C has a 1-5-10-1 structure equaling 81 parameters.\n",
    "\n",
    "$(5 + 5) + (5*10 + 10) + (10 + 1) = 81 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd929e8-c5a4-424e-8da0-c0a4f6747c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network C\n",
    "model_c = Sequential()\n",
    "model_c._name = \"model_c\"\n",
    "model_c.add(Dense(units=5, input_dim=1, activation=\"relu\"))\n",
    "model_c.add(Dense(units=10, input_dim=1, activation=\"relu\"))\n",
    "model_c.add(Dense(units=1, activation=\"relu\"))\n",
    "model_c.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_c.summary()\n",
    "\n",
    "history_model_c = model_c.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14096834-565a-4743-ba3c-12240b6ec493",
   "metadata": {},
   "source": [
    "### Model D\n",
    "\n",
    "Does the order of the layers matter? Model D has a 1-10-5-1 structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf40cbc-cc72-4ef5-b464-07493404fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network D\n",
    "model_d = Sequential()\n",
    "model_d._name = \"model_d\"\n",
    "model_d.add(Dense(units=10, input_dim=1, activation=\"relu\"))\n",
    "model_d.add(Dense(units=5, activation=\"relu\"))\n",
    "model_d.add(Dense(units=1, activation=\"relu\"))\n",
    "model_d.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_d.summary()\n",
    "\n",
    "history_model_d = model_d.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f71ec3-9186-4035-ab24-58f54394a67a",
   "metadata": {},
   "source": [
    "### Model E\n",
    "\n",
    "Adding a fairly extreme number of neurons: 1-100-10-5-1. (1,271 parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01961b4b-f251-470b-8074-ed117da8695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network E\n",
    "model_e = Sequential()\n",
    "model_e._name = \"model_e\"\n",
    "model_e.add(Dense(units=100, input_dim=1, activation=\"relu\"))\n",
    "model_e.add(Dense(units=10, activation=\"relu\"))\n",
    "model_e.add(Dense(units=5, activation=\"relu\"))\n",
    "model_e.add(Dense(units=1, activation=\"relu\"))\n",
    "model_e.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_e.summary()\n",
    "\n",
    "history_model_e = model_e.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "625a47cf-4069-4cb9-9702-7f1f243170cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network(model, history, row):\n",
    "\n",
    "    ax[row, 0].plot(history.history[\"loss\"], label=\"Train\")\n",
    "    ax[row, 0].plot(history.history[\"val_loss\"], label=\"Test\")\n",
    "    ax[row, 0].title.set_text(\"Model loss\")\n",
    "    ax[row, 0].set_xlabel(\"Epoch\")\n",
    "    ax[row, 0].legend()\n",
    "    ax[row, 0].grid(True)\n",
    "\n",
    "    x_predicted = np.linspace(-1, 1, 100)\n",
    "    y_predicted = model.predict(x_predicted)\n",
    "    ax[row, 1].scatter(x_predicted, y_predicted, color=\"r\", s=6, label=\"Prediction\")\n",
    "    ax[row, 1].scatter(x_valid, y_valid, s=2, label=\"Data\")\n",
    "    ax[row, 1].plot(x_valid, y_target, label=\"Theory\")\n",
    "    ax[row, 1].title.set_text(\"Prediction\")\n",
    "    ax[row, 1].legend()\n",
    "    ax[row, 1].grid(True)\n",
    "    ax[row, 1].set_xticklabels([])\n",
    "    ax[row, 1].set_yticklabels([])\n",
    "\n",
    "    lim = 1.25\n",
    "    x_predicted = np.linspace(-lim, lim, 100)\n",
    "    y_predicted = model.predict(x_predicted)\n",
    "    x_extended = np.linspace(-lim, lim, 100)\n",
    "    y_extended = polynomial(x_extended)\n",
    "    ax[row, 2].scatter(x_predicted, y_predicted, color=\"r\", label=\"Guess\")\n",
    "    ax[row, 2].plot(x_extended, y_extended, label=\"Theory\")\n",
    "    ax[row, 2].legend()\n",
    "    ax[row, 2].title.set_text(\"Prediction on Extended Range\")\n",
    "    ax[row, 2].grid(True)\n",
    "    #     ax[row, 2].set_xticklabels([])\n",
    "    ax[row, 2].set_yticklabels([])\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa376c-e6da-4d79-91e2-d6443f8e7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the  networks\n",
    "fig, ax = plt.subplots(5, 3, figsize=(18, 20))\n",
    "# fig.suptitle(\"Models A, B, C, D, E\")\n",
    "\n",
    "ax = plot_network(model_a, history_model_a, 0)\n",
    "ax[0, 0].set_ylabel(\"Model A\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_b, history_model_b, 1)\n",
    "ax[1, 0].set_ylabel(\"Model B\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_c, history_model_c, 2)\n",
    "ax[2, 0].set_ylabel(\"Model C\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_d, history_model_d, 3)\n",
    "ax[3, 0].set_ylabel(\"Model D\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_e, history_model_e, 4)\n",
    "ax[4, 0].set_ylabel(\"Model E\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff92eae-1eb6-4be5-baea-14e2bfa16e1b",
   "metadata": {},
   "source": [
    "- A: 1 neuron\n",
    "- B: 1-5-1\n",
    "- C: 1-5-10-1\n",
    "- D: 1-10-5-1\n",
    "- E: 1-100-10-5-1\n",
    "\n",
    "**Comment.** As expected, Model E (the most complex network) was best suited to the task of identifying the underlying feature. However, none of the networks so far excelled at predicting data out of range. It seems to me that the number of neurons in the network roughly corrisponds with the number of line segments the network is capable of using in order to detect the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6164f3bc-5943-47b2-880f-c4a652efc4e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exploring Built-In Activation functions\n",
    "\n",
    "**relu**, sigmoid, softmax, **softplus**, softsign, tanh, **selu**, **elu**, exponential\n",
    "\n",
    "Activation functions that did not work (no/slow convergence): sigmoid, softmax, softsign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3874b3-004c-4690-8cc8-d01b3d2f4183",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model X\n",
    "\n",
    "Model X is model E with softplus activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bba118-7bc8-48e9-b62e-f2df58291768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network X\n",
    "activation = activations.softplus\n",
    "model_x = Sequential()\n",
    "model_x._name = \"model_x\"\n",
    "model_x.add(Dense(units=100, input_dim=1, activation=activation))\n",
    "model_x.add(Dense(units=10, activation=activation))\n",
    "model_x.add(Dense(units=5, activation=activation))\n",
    "model_x.add(Dense(units=1, activation=activation))\n",
    "model_x.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_x.summary()\n",
    "\n",
    "history_model_x = model_x.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ec9abf-78da-43b2-9ee9-cdf44189b2e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model Y\n",
    "\n",
    "Model Y is model E with selu activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13e329-43e5-4f62-9d34-88f95b5ee558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Y\n",
    "activation = activations.selu\n",
    "model_y = Sequential()\n",
    "model_y._name = \"model_y\"\n",
    "model_y.add(Dense(units=100, input_dim=1, activation=activation))\n",
    "model_y.add(Dense(units=10, activation=activation))\n",
    "model_y.add(Dense(units=5, activation=activation))\n",
    "model_y.add(Dense(units=1, activation=activation))\n",
    "model_y.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_y.summary()\n",
    "\n",
    "history_model_y = model_y.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db85e28-5c51-4f13-9782-5b26a7ba5ec0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model Z\n",
    "\n",
    "Model Z is model E with elu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1894b4-4522-4d2a-809e-a83d7e8ffe54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neural Network Z\n",
    "activation = activations.elu\n",
    "model_z = Sequential()\n",
    "model_z._name = \"model_z\"\n",
    "model_z.add(Dense(units=100, input_dim=1, activation=activation))\n",
    "model_z.add(Dense(units=10, activation=activation))\n",
    "model_z.add(Dense(units=5, activation=activation))\n",
    "model_z.add(Dense(units=1, activation=activation))\n",
    "model_z.compile(optimizer=\"sgd\", loss=\"mse\", metrics=[\"mse\"])\n",
    "model_z.summary()\n",
    "\n",
    "history_model_z = model_z.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e14b0-04cc-4f39-8f10-ebcd923bb51f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b43377-c48f-46c4-9bc8-1265358af07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the  networks\n",
    "fig, ax = plt.subplots(4, 3, figsize=(18, 18))\n",
    "\n",
    "ax = plot_network(model_e, history_model_e, 0)\n",
    "ax[0, 0].set_ylabel(\"Model E\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_x, history_model_x, 1)\n",
    "ax[1, 0].set_ylabel(\"Model X\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_y, history_model_y, 2)\n",
    "ax[2, 0].set_ylabel(\"Model Y\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_z, history_model_z, 3)\n",
    "ax[3, 0].set_ylabel(\"Model Z\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fcabdf-2c76-432c-a1c2-bbb5882ce35c",
   "metadata": {},
   "source": [
    "- E: 1-100-10-5-1, relu\n",
    "- X: 1-100-10-5-1, softplus\n",
    "- Y: 1-100-10-5-1, selu\n",
    "- Z: 1-100-10-5-1, elu\n",
    "\n",
    "**Comment.** Model E (ReLU) and model Z (ELU) seem to be the best for this configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd03af2-61b1-4663-8d29-b82397685697",
   "metadata": {},
   "source": [
    "## Exploring Optimizers\n",
    "\n",
    "**SGD**, **RMSprop**, **Adam**, Adadelta, Adagrad, **Adamax**, **Nadam**, Ftrl\n",
    "\n",
    "(The names in bold are optimizers that proved functional.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eefbe8-7db0-406b-a4a7-4290597ad6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59863338-feef-4a2f-9f1a-c321f2718dc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "### Model U\n",
    "\n",
    "Model U is model E with RMSprop optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb415c9f-e575-4633-a288-79c158aa2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network X\n",
    "activation = activations.relu\n",
    "optimizer = optimizers.RMSprop()\n",
    "model_u = Sequential()\n",
    "model_u._name = \"model_u\"\n",
    "model_u.add(Dense(units=100, input_dim=1, activation=activation))\n",
    "model_u.add(Dense(units=10, activation=activation))\n",
    "model_u.add(Dense(units=5, activation=activation))\n",
    "model_u.add(Dense(units=1, activation=activation))\n",
    "model_u.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "model_u.summary()\n",
    "\n",
    "history_model_u = model_u.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e91bb4-0971-4e74-958d-5cdb13fca3a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model V\n",
    "\n",
    "Model E with Adaptive Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43f070f-0b95-41dd-8f7f-ab5f16270e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network V\n",
    "activation = activations.relu\n",
    "optimizer = optimizers.RMSprop()\n",
    "model_v = Sequential()\n",
    "model_v._name = \"model_v\"\n",
    "model_v.add(Dense(units=100, input_dim=1, activation=activation))\n",
    "model_v.add(Dense(units=10, activation=activation))\n",
    "model_v.add(Dense(units=5, activation=activation))\n",
    "model_v.add(Dense(units=1, activation=activation))\n",
    "model_v.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "model_v.summary()\n",
    "\n",
    "history_model_v = model_v.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0197f4-fefb-4779-808f-620cc7c8bd9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model W\n",
    "\n",
    "Model E with Nadam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983deed-76a3-455e-8742-330b94fa79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network V\n",
    "activation = activations.relu\n",
    "optimizer = optimizers.Nadam()\n",
    "model_w = Sequential()\n",
    "model_w._name = \"model_w\"\n",
    "model_w.add(Dense(units=100, input_dim=1, activation=activation))\n",
    "model_w.add(Dense(units=10, activation=activation))\n",
    "model_w.add(Dense(units=5, activation=activation))\n",
    "model_w.add(Dense(units=1, activation=activation))\n",
    "model_w.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "model_w.summary()\n",
    "\n",
    "history_model_w = model_w.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,  # a good idea : shuffle input at each epoch\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70205e-254d-4495-a59b-dfc03b8f17d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf35d1-ff26-4b0f-bc19-66697814ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the  networks\n",
    "fig, ax = plt.subplots(4, 3, figsize=(18, 18))\n",
    "\n",
    "ax = plot_network(model_e, history_model_e, 0)\n",
    "ax[0, 0].set_ylabel(\"Model E\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_u, history_model_u, 1)\n",
    "ax[1, 0].set_ylabel(\"Model U\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_v, history_model_v, 2)\n",
    "ax[2, 0].set_ylabel(\"Model V\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "ax = plot_network(model_w, history_model_w, 3)\n",
    "ax[3, 0].set_ylabel(\"Model W\", fontsize=\"xx-large\", fontweight=\"semibold\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840775de-c889-4395-a760-621056d5f2a9",
   "metadata": {},
   "source": [
    "- Model E: SGD\n",
    "- Model U: RMSprop\n",
    "- Model V: Adam\n",
    "- Model W: Nadam\n",
    "\n",
    "**Comment.** The final models are all fairly accurate. But the model losses are evidence of the flaw of vanilla stochastic gradient descent: oscillation around the local minimum. However, all other models don't seem to be doing an excellent job. Perhaps they could be improved by changing some of the optimizer parameters.\n",
    "\n",
    "RMSprop, Adam, and Nadam all use momentum to allow the model to \"settle\" into the local minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466efa2a-5e27-48f9-868b-25a00db97b6a",
   "metadata": {},
   "source": [
    "# 11.3 Simple trigonometric 2D function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7c7d1-44bb-4e98-b374-875bb16274d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic(x, y):\n",
    "    return np.sin(x ** 2 + y ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a927b0-c690-4ac8-a65d-dddf5bc10cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise\n",
    "sigma = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925ad5b-cbab-4a7d-8bcd-0d4662e1252a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d584e-e0dc-436f-8b1c-a2d1641fdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 10000\n",
    "\n",
    "# Generate random points (x,y)\n",
    "x_train = np.random.uniform(-3 / 2, 3 / 2, (N_train, 2))\n",
    "x_valid = np.random.uniform(-3 / 2, 3 / 2, (int(N_train / 10), 2))\n",
    "\n",
    "y_target = periodic(x_valid[:, 0], x_valid[:, 1])  # theory\n",
    "y_train = np.random.normal(periodic(x_train[:, 0], x_train[:, 1]), sigma)  # training data\n",
    "y_valid = np.random.normal(periodic(x_valid[:, 0], x_valid[:, 1]), sigma)  # validation data\n",
    "\n",
    "fig = plt.figure(figsize=(20, 5))\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 1, projection=\"3d\")\n",
    "ax = fig.gca(projection=\"3d\")  # to work in 3d\n",
    "ax.scatter(x_train[:, 0], x_train[:, 1], y_train, s=1)\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_zlim(-1.5, 1.5)\n",
    "ax.dist = 8\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2, projection=\"3d\")\n",
    "x_surf = np.arange(-3 / 2, 3 / 2, 0.01)\n",
    "y_surf = np.arange(-3 / 2, 3 / 2, 0.01)\n",
    "x_surf, y_surf = np.meshgrid(x_surf, y_surf)\n",
    "z_surf = periodic(x_surf, y_surf)\n",
    "ax.plot_surface(x_surf, y_surf, z_surf)\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_zlim(-1.5, 1.5)\n",
    "ax.dist = 8\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3, projection=\"3d\")\n",
    "ax.scatter(x_train[:, 0], x_train[:, 1], y_train, s=1, color=\"r\")\n",
    "x_surf = np.arange(-3 / 2, 3 / 2, 0.01)\n",
    "y_surf = np.arange(-3 / 2, 3 / 2, 0.01)\n",
    "x_surf, y_surf = np.meshgrid(x_surf, y_surf)\n",
    "z_surf = periodic(x_surf, y_surf)\n",
    "ax.plot_surface(x_surf, y_surf, z_surf)\n",
    "ax.set_xlim(-1.5, 1.5)\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "ax.set_zlim(-1.5, 1.5)\n",
    "ax.dist = 8\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8ec76-9f08-4c34-918a-5afb1d542528",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2f0fe-2caa-42de-8e63-452b12e60249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "\n",
    "activation = activations.relu\n",
    "optimizer = optimizers.RMSprop()\n",
    "model = Sequential(name=\"Regresion\")\n",
    "model.add(Dense(units=100, input_shape=(2,), activation=activation))\n",
    "model.add(Dense(units=16, activation=activation))\n",
    "model.add(Dense(units=100, activation=activation))\n",
    "model.add(Dense(units=16, activation=activation))\n",
    "model.add(Dense(units=8, activation=activation))\n",
    "model.add(Dense(units=1))  # output layer\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"mse\", metrics=[\"mse\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a162a46-a6c3-44c7-afe8-e2c9a361e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotCurrentEstimate3D(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_valid, y_valid):\n",
    "        \"\"\"Keras Callback which plot current model estimate against reference target\"\"\"\n",
    "\n",
    "        self.x_valid = x_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.iter = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        self.y_curr = self.model.predict(self.x_valid)\n",
    "\n",
    "        self.iter += 1\n",
    "        if self.iter % 10 == 0:  # every 10 epochs\n",
    "            clear_output(wait=True)\n",
    "            self.eplot = plt.subplot(1, 1, 1, projection=\"3d\")\n",
    "            self.eplot.clear()\n",
    "            self.eplot.scatter(\n",
    "                self.x_valid[:, 0], self.x_valid[:, 1], self.y_curr, color=\"blue\", s=4, marker=\"o\", label=\"estimate\",\n",
    "            )\n",
    "            self.eplot.scatter(\n",
    "                self.x_valid[:, 0], self.x_valid[:, 1], self.y_valid, color=\"red\", s=4, marker=\"x\", label=\"valid\",\n",
    "            )\n",
    "            self.eplot.legend()\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c09c4-f80e-4116-8465-de7e2bb3f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [PlotCurrentEstimate3D(x_valid, y_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae7060-58b9-477a-93cd-f26194d7235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epochs = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc032e86-bef8-4337-ae27-1a03c347cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=N_epochs,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2b708-0f19-4cf4-a28b-f3f4296e9aa4",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de841a-2821-4f23-b6b9-f08301b7029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history[\"loss\"], label=\"Train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Test\")\n",
    "plt.title(\"Model loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676cd40-f9e9-436b-84db-9efa72942fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "x_predicted = np.random.uniform(-3 / 2, 3 / 2, (int(N_train / 10), 2))\n",
    "y_predicted = model.predict(x_predicted)\n",
    "ax.scatter(\n",
    "    x_predicted[:, 0], x_predicted[:, 1], y_predicted, s=4, color=\"r\", label=\"Prediction\",\n",
    ")\n",
    "# ax.scatter(\n",
    "#     x_valid[:, 0], x_valid[:, 1], y_valid, s=3, marker=\"*\", color=\"b\", label=\"Validation\",\n",
    "# )\n",
    "\n",
    "ax.plot_surface(x_surf, y_surf, z_surf)\n",
    "\n",
    "# ax.grid(True)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6bb84-29f3-4985-99cd-b4a65f9dbf36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_venv]",
   "language": "python",
   "name": "conda-env-ml_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
